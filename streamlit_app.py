import streamlit as st
import pandas as pd
import re
from pathlib import Path
from io import BytesIO
import requests
from urllib.parse import quote_plus
import smtplib
from email.message import EmailMessage

# Optional heavy imports
try:
    from PyPDF2 import PdfReader
except Exception:
    PdfReader = None
try:
    import docx
except Exception:
    docx = None
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import linear_kernel
except Exception:
    TfidfVectorizer = None
    linear_kernel = None
try:
    from bs4 import BeautifulSoup
except Exception:
    BeautifulSoup = None
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    S2_AVAILABLE = True
    S2_MODEL = SentenceTransformer('all-MiniLM-L6-v2')
except Exception:
    S2_AVAILABLE = False
    S2_MODEL = None


st.set_page_config(page_title='ì¡ë°ë ë¼', page_icon='ğŸ«§', layout='wide')


def local_css():
    css = '''
    <style>
    .stApp { background: linear-gradient(180deg, #FFF8FB 0%, #FFFDF8 100%);} 
    .big-logo {font-size:42px; font-weight:700; color:#FF6FA3;}
    .subtitle {color:#9B6DFF; font-size:18px}
    .card {background:#ffffff80; border-radius:14px; padding:12px;}
    .rounded {border-radius:12px}
    .pastel-btn {background: linear-gradient(90deg,#FFD1DC,#D6C3FF); color:#222; border:none; padding:8px 12px; border-radius:10px}
    </style>
    '''
    st.markdown(css, unsafe_allow_html=True)


@st.cache_data
def load_jobs():
    fn = Path(__file__).parent / 'data' / 'jobs_mock.csv'
    if fn.exists():
        return pd.read_csv(fn)
    else:
        return pd.DataFrame(columns=['company','title','region','salary','exp_level','description','url'])


def extract_text_from_pdf(file_bytes):
    if PdfReader is None:
        return ''
    try:
        reader = PdfReader(BytesIO(file_bytes))
        text = []
        for p in reader.pages:
            text.append(p.extract_text() or '')
        return '\n'.join(text)
    except Exception:
        return ''


def extract_text_from_docx(file_bytes):
    if docx is None:
        return ''
    try:
        doc = docx.Document(BytesIO(file_bytes))
        return '\n'.join([p.text for p in doc.paragraphs])
    except Exception:
        return ''


def parse_resume(uploaded_file):
    data = uploaded_file.read()
    name = uploaded_file.name.lower()
    if name.endswith('.pdf'):
        return extract_text_from_pdf(data)
    if name.endswith('.docx') or name.endswith('.doc'):
        return extract_text_from_docx(data)
    try:
        return data.decode('utf-8', errors='ignore')
    except Exception:
        return ''


def extract_keywords_tfidf(text, top_n=10):
    if TfidfVectorizer is None:
        return []
    vec = TfidfVectorizer(stop_words='english', max_features=2000)
    tfidf = vec.fit_transform([text])
    indices = tfidf.toarray()[0].argsort()[::-1][:top_n]
    features = vec.get_feature_names_out()
    return [features[i] for i in indices]


def recommend_jobs(resume_text, jobs_df, top_n=5, use_transformer=False):
    if jobs_df.empty or not resume_text.strip():
        return jobs_df.head(0)
    if use_transformer and S2_AVAILABLE:
        corpus = jobs_df['description'].fillna('').tolist()
        emb = S2_MODEL.encode(corpus, convert_to_numpy=True)
        r_emb = S2_MODEL.encode([resume_text], convert_to_numpy=True)
        sims = cosine_similarity(r_emb, emb).flatten()
        jobs = jobs_df.copy()
        jobs['score'] = sims
        return jobs.sort_values('score', ascending=False).head(top_n)
    # fallback TF-IDF
    if TfidfVectorizer is None:
        return jobs_df.head(0)
    corpus = jobs_df['description'].fillna('')
    vect = TfidfVectorizer(stop_words='english')
    tfidf = vect.fit_transform(corpus.tolist() + [resume_text])
    resume_vec = tfidf[-1]
    job_vecs = tfidf[:-1]
    cosine_sim = linear_kernel(resume_vec, job_vecs).flatten()
    jobs = jobs_df.copy()
    jobs['score'] = cosine_sim
    return jobs.sort_values('score', ascending=False).head(top_n)


def resume_feedback(text):
    suggestions = []
    if not re.search(r'\b(ì´ë¦„|ì—°ë½ì²˜|ì „í™”ë²ˆí˜¸|email|ì´ë©”ì¼)\b', text, re.I):
        suggestions.append('ì—°ë½ì²˜ë‚˜ ì´ë©”ì¼ ì •ë³´ê°€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.')
    if not re.search(r'\b(ê²½ë ¥|ê²½ë ¥ì‚¬í•­|ì§ë¬´)\b', text):
        suggestions.append('ê²½ë ¥(ì§ë¬´) ì„¹ì…˜ì„ ë” ìì„¸íˆ ì‘ì„±í•´ë³´ì„¸ìš”.')
    if not re.search(r'\b(í•™ë ¥|í•™êµ|ì¡¸ì—…)\b', text):
        suggestions.append('í•™ë ¥ ì •ë³´ë¥¼ ì¶”ê°€í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.')
    years = re.findall(r'(?:(19|20)\d{2})', text)
    if len(years) >= 2:
        suggestions.append('ì—°ë„ í‘œê¸°ê°€ ì‚°ì¬í•´ ìˆìŠµë‹ˆë‹¤. ê³µë°± ê¸°ê°„ì€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.')
    common_skills = ['python','sql','excel','java','javascript','react','aws','docker']
    found = [s for s in common_skills if re.search(r'\b'+s+'\b', text, re.I)]
    if not found:
        suggestions.append('ìì£¼ ìš”ì²­ë˜ëŠ” ìŠ¤í‚¬(ì˜ˆ: Python, SQL ë“±)ì„ ëª…ì‹œí•´ ë³´ì„¸ìš”.')
    if not suggestions:
        suggestions.append('ì´ë ¥ì„œê°€ ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•´ ë³´ì…ë‹ˆë‹¤. ì„¸ë¶€ ì„±ê³¼ë¥¼ ë” ìˆ˜ì¹˜í™”í•´ë³´ì„¸ìš”.')
    return suggestions


def jobkorea_search(query, region=None, exp=None, pages=1):
    """
    ì‹œë„í˜• ê°„ë‹¨ ìŠ¤í¬ë˜í¼: ì¡ì½”ë¦¬ì•„ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ê³µê³  ë§í¬/íƒ€ì´í‹€ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    ì‹¤íŒ¨ ì‹œ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜.
    """
    results = []
    if BeautifulSoup is None:
        return pd.DataFrame(results, columns=['company','title','region','salary','exp_level','description','url'])
    base = 'https://www.jobkorea.co.kr/Search/?stext='
    q = quote_plus(query)
    try:
        for p in range(1, pages+1):
            url = f'{base}{q}&Page_No={p}'
            r = requests.get(url, timeout=8, headers={'User-Agent':'Mozilla/5.0'})
            if r.status_code != 200:
                continue
            soup = BeautifulSoup(r.text, 'html.parser')
            # find links to recruitment pages
            for a in soup.find_all('a', href=True):
                href = a['href']
                if '/Recruit/' in href or '/Co/' in href:
                    title = a.get_text(strip=True)
                    link = requests.compat.urljoin('https://www.jobkorea.co.kr', href)
                    results.append({'company':'','title':title,'region':'','salary':None,'exp_level':'','description':'','url':link})
            if len(results) >= 50:
                break
    except Exception:
        return pd.DataFrame(results, columns=['company','title','region','salary','exp_level','description','url'])
    return pd.DataFrame(results, columns=['company','title','region','salary','exp_level','description','url'])


def send_email(smtp_server, smtp_port, username, password, to_email, subject, body, attachments=None):
    msg = EmailMessage()
    msg['Subject'] = subject
    msg['From'] = username
    msg['To'] = to_email
    msg.set_content(body)
    if attachments:
        for name, content, mime in attachments:
            msg.add_attachment(content, maintype=mime.split('/')[0], subtype=mime.split('/')[1], filename=name)
    try:
        if smtp_port == 465:
            server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        else:
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
        server.login(username, password)
        server.send_message(msg)
        server.quit()
        return True, 'Sent'
    except Exception as e:
        return False, str(e)


def to_csv_download(df):
    return df.to_csv(index=False).encode('utf-8')


def main():
    local_css()
    jobs = load_jobs()

    if 'first_visit' not in st.session_state:
        st.session_state.first_visit = True

    with st.sidebar:
        st.markdown('<div class="big-logo">ì¡ë°ë ë¼</div>', unsafe_allow_html=True)
        st.markdown('<div class="subtitle">ë‹¹ì‹ ì˜ ë™í™” ê°™ì€ ì»¤ë¦¬ì–´ë¥¼ ì‹œì‘í•˜ëŠ” ê³³, ì¡ë°ë ë¼!</div>', unsafe_allow_html=True)
        menu = st.radio('ë©”ë‰´', ['ì´ë ¥ì„œ ì—…ë¡œë“œ','ì¶”ì²œ ì±„ìš© ê³µê³ ','ì§ë¬´ ì¸í„°ë·°','í•©ê²©ìì†Œì„œ ì˜ˆì‹œ','ì½˜í…ì¸ LAB','ì·¨ì—…í†¡í†¡'])
        st.markdown('---')
        st.caption('ì‹¤ì‹œê°„ ì¡ì½”ë¦¬ì•„ ì—°ë™ ë° ì´ë©”ì¼ ì „ì†¡ì€ ì„ íƒ ê¸°ëŠ¥ì…ë‹ˆë‹¤.')

    if st.session_state.first_visit:
        st.session_state.first_visit = False
        st.info('ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì¡ë°ë ë¼ê°€ ë§ì¶¤í˜• ì¶”ì²œê³¼ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤!')

    col1, col2 = st.columns([3,1])
    with col1:
        st.markdown('<div class="big-logo">ğŸ«§ ì¡ë°ë ë¼</div>', unsafe_allow_html=True)
        st.markdown('<div class="subtitle">ë§ì¶¤í˜• ì»¤ë¦¬ì–´ ì¶”ì²œ ì„œë¹„ìŠ¤</div>', unsafe_allow_html=True)
    with col2:
        st.button('í”„ë¡œí•„ ì„¤ì •', disabled=True)

    if menu == 'ì´ë ¥ì„œ ì—…ë¡œë“œ':
        st.header('ì´ë ¥ì„œ ì—…ë¡œë“œ')
        st.markdown('PDF ë˜ëŠ” Word(.docx) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„í•©ë‹ˆë‹¤.')
        uploaded = st.file_uploader('ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”', type=['pdf','docx','doc'], accept_multiple_files=False)
        if uploaded is not None:
            text = parse_resume(uploaded)
            st.success('ì´ë ¥ì„œê°€ ì—…ë¡œë“œë˜ì–´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.')
            st.subheader('ì´ë ¥ì„œ ìš”ì•½')
            st.text_area('ì›ë¬¸', value=text[:5000], height=250)
            st.subheader('ì¶”ì¶œëœ í‚¤ì›Œë“œ')
            kws = extract_keywords_tfidf(text, top_n=12)
            st.write(', '.join(kws))
            st.subheader('ê°œì„  í”¼ë“œë°±')
            for s in resume_feedback(text):
                st.write('- ' + s)
            st.session_state['resume_text'] = text

    elif menu == 'ì¶”ì²œ ì±„ìš© ê³µê³ ':
        st.header('ì¶”ì²œ ì±„ìš© ê³µê³ ')
        resume_text = st.session_state.get('resume_text','')
        st.sidebar.markdown('---')
        use_live = st.sidebar.checkbox('ì¡ì½”ë¦¬ì•„ ì‹¤ì‹œê°„ ì—°ë™(ì‹œë„)', value=False)
        use_transformer = st.sidebar.checkbox('ê³ ê¸‰ NLP(ì„ë² ë”©) ì‚¬ìš©', value=S2_AVAILABLE)
        regions = ['ì „ì²´'] + sorted(jobs['region'].dropna().unique().tolist())
        chosen_region = st.sidebar.selectbox('ì§€ì—­', regions)
        exp_filter = st.sidebar.selectbox('ê²½ë ¥', ['ì „ì²´','ì‹ ì…','ê²½ë ¥'])
        salary_min = st.sidebar.number_input('ìµœì € ì—°ë´‰(ë§Œì›)', value=0, step=100)

        if use_live and resume_text:
            # build a simple query from top keywords
            kws = extract_keywords_tfidf(resume_text, top_n=5)
            query = ' '.join(kws) if kws else resume_text.split()[:5]
            live = jobkorea_search(query, pages=1)
            df_candidates = pd.concat([live, jobs], ignore_index=True, sort=False).drop_duplicates(subset=['title','url'], keep='first')
        else:
            df_candidates = jobs.copy()

        if resume_text:
            recs = recommend_jobs(resume_text, df_candidates, top_n=50, use_transformer=use_transformer)
        else:
            recs = df_candidates.copy()

        if chosen_region != 'ì „ì²´':
            recs = recs[recs['region']==chosen_region]
        if exp_filter != 'ì „ì²´':
            recs = recs[recs['exp_level'].str.contains(exp_filter, na=False)]
        if salary_min > 0:
            recs = recs[recs['salary'].fillna(0) >= salary_min]

        st.write(f'ì¶”ì²œ ê³µê³ : {len(recs)}ê°œ')
        if not recs.empty:
            display = recs[['company','title','region','salary']].reset_index(drop=True)
            st.dataframe(display)
            idx = st.number_input('ìƒì„¸ë³´ê¸°: ê³µê³  ì„ íƒ(ë²ˆí˜¸)', min_value=0, max_value=max(0,len(display)-1), value=0)
            job = recs.reset_index(drop=True).iloc[int(idx)]
            st.subheader(job.get('title',''))
            st.write('íšŒì‚¬:', job.get('company',''))
            st.write('ì§€ì—­:', job.get('region',''))
            st.write('ì—°ë´‰(ë§Œì›):', job.get('salary',''))
            st.write('ìƒì„¸:', job.get('description',''))
            st.markdown(f'[ê³µê³ ë¡œ ì´ë™]({job.get("url","#")})')

            if st.button('ì„ íƒ ê³µê³  CSVë¡œ ì €ì¥'):
                csv = to_csv_download(pd.DataFrame([job]))
                st.download_button('ë‹¤ìš´ë¡œë“œ', csv, file_name='job_export.csv', mime='text/csv')

            st.markdown('---')
            st.subheader('ì´ë©”ì¼ë¡œ ì „ì†¡(ì„¤ì • í•„ìš”)')
            smtp_server = st.text_input('SMTP ì„œë²„ (ì˜ˆ: smtp.gmail.com)', value='')
            smtp_port = st.number_input('í¬íŠ¸', value=465)
            smtp_user = st.text_input('ë³´ë‚´ëŠ” ì´ë©”ì¼(ê³„ì •)', value='')
            smtp_pass = st.text_input('ë¹„ë°€ë²ˆí˜¸(ì•± ë¹„ë°€ë²ˆí˜¸ ê¶Œì¥)', type='password')
            to_email = st.text_input('ë°›ëŠ” ì´ë©”ì¼', value='')
            if st.button('ì´ë©”ì¼ ì „ì†¡(ì‹¤ì œ)'):
                if not all([smtp_server, smtp_port, smtp_user, smtp_pass, to_email]):
                    st.error('SMTP ì„¤ì •ê³¼ ë°›ëŠ” ì´ë©”ì¼ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.')
                else:
                    subject = f"[ì¡ë°ë ë¼] ì¶”ì²œ ê³µê³ : {job.get('title','')}"
                    body = f"íšŒì‚¬: {job.get('company','')}\nì§€ì—­: {job.get('region','')}\nì—°ë´‰: {job.get('salary','')}\n\nìƒì„¸: {job.get('description','')}\në§í¬: {job.get('url','')}"
                    ok, msg = send_email(smtp_server, int(smtp_port), smtp_user, smtp_pass, to_email, subject, body, attachments=None)
                    if ok:
                        st.success('ì´ë©”ì¼ ì „ì†¡ ì„±ê³µ')
                    else:
                        st.error('ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: ' + msg)
        else:
            st.info('ì¡°ê±´ì— ë§ëŠ” ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.')

    elif menu == 'ì§ë¬´ ì¸í„°ë·°':
        st.header('ì§ë¬´ ì¸í„°ë·°')
        st.markdown('ì—…ë¡œë“œí•œ ì´ë ¥ì„œì™€ ì—°ê²°ëœ ì§ë¬´ì˜ ì¸í„°ë·° íŒê³¼ ëª¨ì˜ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.')
        resume_text = st.session_state.get('resume_text','')
        if not resume_text:
            st.info('ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë§ì¶¤í˜• ì¸í„°ë·° ì½˜í…ì¸ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.')
        else:
            kws = extract_keywords_tfidf(resume_text, top_n=8)
            st.subheader('ì¶”ì²œ ì¸í„°ë·° ì£¼ì œ')
            for k in kws[:6]:
                st.write('- ' + k)
            st.subheader('ëª¨ì˜ ì§ˆë¬¸')
            st.write('1) ìµœê·¼ ë‹´ë‹¹í•œ í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?')
            st.write('2) í•´ë‹¹ ì§ë¬´ì—ì„œ ì¤‘ìš”í•œ í•µì‹¬ ì—­ëŸ‰ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?')

    elif menu == 'í•©ê²©ìì†Œì„œ ì˜ˆì‹œ':
        st.header('í•©ê²©ìì†Œì„œ ì˜ˆì‹œ')
        st.markdown('ì—…ë¡œë“œ ì´ë ¥ì„œì˜ ì§ë¬´ì— ë§ì¶˜ í•©ê²©ìì†Œì„œ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.')
        st.write('ì˜ˆì‹œ 1: [ì§€ì›ë™ê¸° ë° ê²½í—˜ ê¸°ë°˜ ì‚¬ë¡€ ì„¤ëª…] ...')

    elif menu == 'ì½˜í…ì¸ LAB':
        st.header('ì½˜í…ì¸ LAB')
        st.write('ì§ë¬´ë³„ ê³µë¶€ìë£Œ, ì¶”ì²œ ê°•ì˜, ë§ˆì¸ë“œì…‹ ì½˜í…ì¸ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.')
        st.write('- Python ê¸°ì´ˆ ê°•ì˜: ì¸í”„ëŸ°/íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ë“±')

    else:
        st.header('ì·¨ì—…í†¡í†¡')
        st.write('ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ì§ˆë¬¸ê³¼ ë‹µë³€ (ì˜ˆì‹œ ê¸°ëŠ¥)')


if __name__ == '__main__':
    main()
